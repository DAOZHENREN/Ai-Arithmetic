{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from skimage import morphology, filters\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm  # 导入tqdm库\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, MaxPooling2D, Softmax, Activation, BatchNormalization, \\\n",
    "    Flatten, Dropout, DepthwiseConv2D\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "NUM = 14"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "url = \"https://file.liux.pro/mnist14.zip\"\n",
    "path_to_zip = tf.keras.utils.get_file(origin=url, cache_dir=\".\", cache_subdir=\"dataset\", extract=True)\n",
    "dataset_dir  = os.path.join(os.path.dirname(path_to_zip), 'mnist14')\n",
    "print(dataset_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T10:24:02.909389Z",
     "iopub.status.busy": "2024-10-31T10:24:02.909111Z",
     "iopub.status.idle": "2024-10-31T10:24:19.166729Z",
     "shell.execute_reply": "2024-10-31T10:24:19.165832Z",
     "shell.execute_reply.started": "2024-10-31T10:24:02.909361Z"
    },
    "trusted": true
   },
   "source": [
    "# 定义数据集路径\n",
    "data_folder = dataset_dir\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "x_data_original = []  # 用于存储原始图像\n",
    "\n",
    "\n",
    "# 定义细化处理函数\n",
    "def thin_image(image):\n",
    "    binary_image = image > filters.threshold_otsu(image)\n",
    "    skeleton = morphology.skeletonize(binary_image)\n",
    "    thin_image = (skeleton * 255).astype(np.uint8)\n",
    "    return thin_image\n",
    "\n",
    "\n",
    "def resize_with_black_border(image, ratioX, ratioY):\n",
    "    # 获取原始图像大小\n",
    "    original_width, original_height = image.size\n",
    "\n",
    "    # 根据比例计算缩放后的尺寸\n",
    "    new_width = int(original_width * ratioX)\n",
    "    new_height = int(original_height * ratioY)\n",
    "\n",
    "    # 缩小图像\n",
    "    resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # 创建一个黑色背景的新图像，大小与原图相同\n",
    "    new_image = Image.new('L', (original_width, original_height), color=0)  # 'L' 模式为灰度图\n",
    "\n",
    "    # 将缩小后的图像粘贴到黑色背景的中央\n",
    "    left = (original_width - new_width) // 2\n",
    "    top = (original_height - new_height) // 2\n",
    "    new_image.paste(resized_image, (left, top))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# 加载图像和标签\n",
    "for label in range(NUM):\n",
    "    label_folder = os.path.join(data_folder, str(label))\n",
    "    images = []\n",
    "    original_images = []\n",
    "\n",
    "    # 使用tqdm显示进度条\n",
    "    for img_name in tqdm(os.listdir(label_folder), desc=f'Loading images for label {label}'):\n",
    "        img_path = os.path.join(label_folder, img_name)\n",
    "\n",
    "        # 加载并处理图像\n",
    "        image = Image.open(img_path).convert('L')  # 转换为灰度图\n",
    "        image = image.resize((28, 28))  # 调整大小\n",
    "        if label == 0:\n",
    "            image = resize_with_black_border(image, 0.7, 0.9)\n",
    "\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        # 存储原始图像\n",
    "        original_images.append(image_array)\n",
    "\n",
    "        # 细化处理\n",
    "        image_array = thin_image(image_array)\n",
    "\n",
    "        images.append(image_array)\n",
    "\n",
    "    x_data.extend(images)\n",
    "    y_data.extend([label] * len(images))\n",
    "    x_data_original.extend(original_images)\n",
    "\n",
    "# 转换为NumPy数组\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "x_data_original = np.array(x_data_original)\n",
    "\n",
    "# 直接使用所有样本\n",
    "x_balanced = x_data\n",
    "y_balanced = y_data\n",
    "\n",
    "# 按比例拆分数据集（例如，80% 训练集，20% 测试集）\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# 确保数据集的形状符合TensorFlow的要求\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "# 创建一个ImageDataGenerator实例并设置增强参数\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=1,\n",
    "    zoom_range=(0.8, 1.0),\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "# 适配数据生成器\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 打印每种图片的数量\n",
    "unique, counts = np.unique(y_balanced, return_counts=True)\n",
    "print(\"每种图片数量:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f'类别 {label}: {count} 张')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 显示几个原始图像与细化后的对比图\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 10))\n",
    "\n",
    "# 显示几个样本\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        idx = np.random.choice(len(x_data))  # 随机选择一个索引\n",
    "        axes[i, j * 2].imshow(x_data_original[idx], cmap='gray')\n",
    "        axes[i, j * 2].set_title(f\"original,Label: {y_balanced[idx]}\")\n",
    "        axes[i, j * 2].axis('off')\n",
    "\n",
    "        axes[i, j * 2 + 1].imshow(x_data[idx], cmap='gray')\n",
    "        axes[i, j * 2 + 1].set_title(f\"thin,Label: {y_balanced[idx]}\")\n",
    "        axes[i, j * 2 + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T10:24:19.178160Z",
     "iopub.status.busy": "2024-10-31T10:24:19.177789Z",
     "iopub.status.idle": "2024-10-31T10:24:19.188291Z",
     "shell.execute_reply": "2024-10-31T10:24:19.187360Z",
     "shell.execute_reply.started": "2024-10-31T10:24:19.178106Z"
    },
    "trusted": true
   },
   "source": [
    "# (x_train,y_train), (x_test,y_test) = mnist.load_data() "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T10:24:19.189748Z",
     "iopub.status.busy": "2024-10-31T10:24:19.189437Z",
     "iopub.status.idle": "2024-10-31T10:24:19.226422Z",
     "shell.execute_reply": "2024-10-31T10:24:19.225601Z",
     "shell.execute_reply.started": "2024-10-31T10:24:19.189717Z"
    },
    "trusted": true
   },
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1) / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1) / 255\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=NUM)\n",
    "y_test = to_categorical(y_test, num_classes=NUM)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def init_model(dim0):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 第一个卷积层\n",
    "    model.add(Conv2D(dim0 * 8, (3, 3), padding='same', strides=(2, 2),\n",
    "                     input_shape=(28, 28, 1), name='ftr0a'))\n",
    "    model.add(BatchNormalization(name=\"bn0\"))\n",
    "    model.add(Activation('relu', name=\"relu0\"))\n",
    "    model.add(Dropout(0.3))  # 添加 Dropout 层\n",
    "\n",
    "    # # 第一个深度可分离卷积层\n",
    "    # model.add(DepthwiseConv2D((3, 3), padding='same', name='ftr0b'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation('relu', name=\"relu00\"))\n",
    "    # model.add(Dropout(0.3))  # 添加 Dropout 层\n",
    "\n",
    "    # 第二个卷积层\n",
    "    model.add(Conv2D(dim0 * 1, (3, 3), padding='same', strides=(2, 2), name='ftr1a'))\n",
    "    model.add(BatchNormalization(name=\"bn1\"))\n",
    "    model.add(Activation('relu', name=\"relu1\"))\n",
    "\n",
    "    # # 第二个深度可分离卷积层\n",
    "    # model.add(DepthwiseConv2D((3, 3), padding='same', depth_multiplier=2, name='ftr1b'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation('relu', name=\"relu11\"))\n",
    "    # model.add(Dropout(0.3))  # 添加 Dropout 层\n",
    "\n",
    "    # # 全局平均池化层\n",
    "    # model.add(GlobalAveragePooling2D(name='GAP'))\n",
    "    # model.add(Dropout(0.3))  # 添加 Dropout 层\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # # 全连接层\n",
    "    # model.add(Dense(16, name=\"fc1\"))\n",
    "    # model.add(Activation('softmax', name=\"sm1\"))\n",
    "    # model.add(Dropout(0.3))  # 添加 Dropout 层\n",
    "\n",
    "    # 全连接层\n",
    "    model.add(Dense(NUM, name=\"fc2\"))\n",
    "    model.add(Dropout(0.3))  # 添加 Dropout 层\n",
    "    model.add(Activation('softmax', name=\"sm2\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# 设置参数并初始化模型\n",
    "DIM0 = 3\n",
    "model = init_model(DIM0)\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T10:24:19.451167Z",
     "iopub.status.busy": "2024-10-31T10:24:19.450856Z",
     "iopub.status.idle": "2024-10-31T10:27:24.817605Z",
     "shell.execute_reply": "2024-10-31T10:27:24.816715Z",
     "shell.execute_reply.started": "2024-10-31T10:24:19.451135Z"
    },
    "trusted": true
   },
   "source": [
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "# 创建数据增强生成器\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size=128)\n",
    "\n",
    "# 定义早停回调\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# 定义模型检查点回调，保存验证损失最小的模型\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# 使用数据生成器进行训练，并获取 History 对象\n",
    "history = model.fit(train_generator,\n",
    "                    batch_size=1280,\n",
    "                    epochs=30,\n",
    "                    verbose=2,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    shuffle=True,\n",
    "                    max_queue_size=100,\n",
    "                    workers = 8,\n",
    "                    use_multiprocessing=True,)\n",
    "\n",
    "# 加载最佳模型权重\n",
    "model.load_weights('best_model.h5')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# 绘制训练和验证的损失和准确率曲线\n",
    "def plot_training_history(history):\n",
    "    # 绘制训练 & 验证损失值\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # 绘制训练 & 验证准确率值\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['categorical_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_categorical_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_training_history(history)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'\\n测试集的总体准确率: {test_acc:.2f}')\n",
    "\n",
    "# 获取预测结果\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "# 绘制混淆矩阵图\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(NUM), yticklabels=range(NUM))\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'\\n测试集的总体准确率: {test_acc:.2f}')\n",
    "\n",
    "# 获取预测结果\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 计算每种类别的错误率\n",
    "error_rates = {}\n",
    "for label in range(NUM):\n",
    "    label_indices = np.where(y_test_classes == label)[0]\n",
    "    label_correct = np.sum(y_pred_classes[label_indices] == y_test_classes[label_indices])\n",
    "    label_total = len(label_indices)\n",
    "    label_error_rate = 1 - (label_correct / label_total)\n",
    "    error_rates[label] = label_error_rate\n",
    "\n",
    "print(\"\\n每种类别的错误率:\")\n",
    "for label, error_rate in error_rates.items():\n",
    "    print(f'类别 {label}: {error_rate:.2f}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 导出模型\n",
    "# model.save(\"mnist.h5\")\n",
    "model.export(\"mnist\")\n",
    "# 调用转换脚本\n",
    "!python tools/h5_to_tflite.py mnist mnist.tflite 1 dataset/mnist14  0to1\n",
    "!python tools/tflite2tmdl.py mnist.tflite mnist.tmdl int8 1 28,28,1 {NUM} 1"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
